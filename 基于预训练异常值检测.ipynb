{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#自编码器（Autoencoder）是一种非常适合用于异常值检测的神经网络结构，特别是在无法获得大量带标签异常样本的情况下。它们通常被训练为只重建正常数据的分布，所以当输入的是异常数据时，重建误差会较大，从而可以用来检测异常。\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T02:50:40.771713900Z",
     "start_time": "2024-01-25T02:50:40.725836200Z"
    }
   },
   "id": "ab5d9103b2e1e4e4"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def create_autoencoder(input_shape):\n",
    "    # 编码器\n",
    "    encoder = models.Sequential([\n",
    "        layers.InputLayer(input_shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'), # 将得到 65x65\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'), # 将得到 33x33\n",
    "    ])\n",
    "    \n",
    "    # 解码器\n",
    "    decoder = models.Sequential([\n",
    "        layers.Conv2DTranspose(16, (3, 3), strides=2, activation='relu', padding='same'), # 应该会扩展到 66x66\n",
    "        layers.Cropping2D(cropping=((1, 0), (1, 0))), # 裁剪到 65x65\n",
    "        layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same'), # 应该会扩展到 130x130\n",
    "        layers.Cropping2D(cropping=((1, 0), (1, 0))), # 裁剪到 129x129\n",
    "        layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    \n",
    "    autoencoder = models.Sequential([encoder, decoder])\n",
    "    return autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T03:55:36.844325700Z",
     "start_time": "2024-01-25T03:55:36.793439Z"
    }
   },
   "id": "1fe619c348ca01ac"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "autoencoder = create_autoencoder((129, 129, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T03:55:37.071755600Z",
     "start_time": "2024-01-25T03:55:37.016902Z"
    }
   },
   "id": "631189dfd320f132"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#图像预处理归一化\n",
    "def preprocess_image(image):\n",
    "    # 计算每张图像的最小值和最大值\n",
    "    min_value = tf.reduce_min(image)\n",
    "    max_value = tf.reduce_max(image)\n",
    "\n",
    "    # 线性缩放图像数据到[-1, 1]\n",
    "    image_normalized = (image - min_value) / (max_value - min_value) * 2.0 - 1.0\n",
    "    \n",
    "    # 确保图像数据类型为float32\n",
    "    image_normalized = tf.cast(image_normalized, tf.float32)\n",
    "    \n",
    "    # 增加一个通道维度（变成形状 [129, 129, 1]）\n",
    "    image_normalized = tf.expand_dims(image_normalized, axis=-1)\n",
    "    \n",
    "    return image_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T03:26:40.632402700Z",
     "start_time": "2024-01-25T03:26:40.577514700Z"
    }
   },
   "id": "bd4a86a2f56e9530"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_data = np.load('D:/科大研究生生活/文章/2023.10后补充工作/数据/按炮划分数据/第三次筛选/val_output.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T03:14:09.673028700Z",
     "start_time": "2024-01-25T03:14:08.178442700Z"
    }
   },
   "id": "6fde46df94955759"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_data = tf.convert_to_tensor(train_data, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T03:31:49.978239500Z",
     "start_time": "2024-01-25T03:31:49.937333600Z"
    }
   },
   "id": "64b2231c31c48153"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# 创建 TensorFlow 数据集对象\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_data))\n",
    "\n",
    "# 应用预处理函数\n",
    "train_dataset = train_dataset.map(lambda x, y: (preprocess_image(x), preprocess_image(y)))  #逐张图像计算最大/最小值"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T03:32:24.435240Z",
     "start_time": "2024-01-25T03:32:24.369415400Z"
    }
   },
   "id": "ba6856320946073f"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# 设置批量大小\n",
    "batch_size = 32\n",
    "\n",
    "# 批处理和预取\n",
    "train_dataset = train_dataset.batch(batch_size).repeat()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T03:32:36.314183800Z",
     "start_time": "2024-01-25T03:32:36.264317600Z"
    }
   },
   "id": "3c2af58764383d9a"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# 调用你之前定义的模型创建函数\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T03:55:41.812877200Z",
     "start_time": "2024-01-25T03:55:41.758444400Z"
    }
   },
   "id": "e3441a56668cca7c"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "75/75 [==============================] - 20s 255ms/step - loss: 0.4208\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 22s 295ms/step - loss: 0.2584\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 21s 277ms/step - loss: 0.2582\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 21s 279ms/step - loss: 0.2591\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 19s 249ms/step - loss: 0.2584\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 18s 235ms/step - loss: 0.2582\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 18s 241ms/step - loss: 0.2582\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 19s 259ms/step - loss: 0.2577\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 20s 264ms/step - loss: 0.2581\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 19s 258ms/step - loss: 0.2567\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 20s 260ms/step - loss: 0.2567\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 20s 259ms/step - loss: 0.2578\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 18s 240ms/step - loss: 0.2572\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 19s 249ms/step - loss: 0.2574\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 18s 246ms/step - loss: 0.2573\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 17s 229ms/step - loss: 0.2570\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 18s 234ms/step - loss: 0.2580\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 19s 248ms/step - loss: 0.2579\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 18s 240ms/step - loss: 0.2580\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 18s 240ms/step - loss: 0.2574\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 18s 238ms/step - loss: 0.2574\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 18s 241ms/step - loss: 0.2580\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 18s 245ms/step - loss: 0.2574\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 19s 248ms/step - loss: 0.2574\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 18s 238ms/step - loss: 0.2574\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 18s 244ms/step - loss: 0.2574\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 18s 238ms/step - loss: 0.2580\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 18s 234ms/step - loss: 0.2579\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 19s 251ms/step - loss: 0.2576\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 18s 245ms/step - loss: 0.2577\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 19s 250ms/step - loss: 0.2571\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 19s 251ms/step - loss: 0.2577\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 19s 249ms/step - loss: 0.2579\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 18s 240ms/step - loss: 0.2575\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 18s 233ms/step - loss: 0.2576\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 18s 234ms/step - loss: 0.2574\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 18s 241ms/step - loss: 0.2577\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 17s 232ms/step - loss: 0.2575\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 18s 241ms/step - loss: 0.2567\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 18s 241ms/step - loss: 0.2574\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 18s 238ms/step - loss: 0.2574\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 18s 237ms/step - loss: 0.2573\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 18s 241ms/step - loss: 0.2580\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 17s 228ms/step - loss: 0.2569\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 18s 234ms/step - loss: 0.2572\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 17s 229ms/step - loss: 0.2575\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 17s 229ms/step - loss: 0.2573\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 19s 249ms/step - loss: 0.2576\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 17s 227ms/step - loss: 0.2575\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 17s 233ms/step - loss: 0.2571\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "history = autoencoder.fit(train_dataset, epochs=50, steps_per_epoch=len(train_data) // batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T04:11:01.748418700Z",
     "start_time": "2024-01-25T03:55:42.246997800Z"
    }
   },
   "id": "cd51ab0b322f240c"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "autoencoder.save('D:/科大研究生生活/课题/异常值检测/模型/autoencoder1.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T09:07:33.696254700Z",
     "start_time": "2024-01-25T09:07:33.624355500Z"
    }
   },
   "id": "5541e0a2550d0d28"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "test_data1 = np.load('D:/科大研究生生活/文章/2023.10后补充工作/数据/按炮划分数据/第三次筛选/test_output.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:52:55.015675Z",
     "start_time": "2024-01-25T08:52:54.895682Z"
    }
   },
   "id": "1013ddab11dab808"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "test_data1 = tf.convert_to_tensor(test_data1,dtype=tf.float32)\n",
    "test_set1 = tf.data.Dataset.from_tensor_slices(test_data1)\n",
    "test_set1 = test_set1.map(lambda x: (preprocess_image(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:46:58.527451700Z",
     "start_time": "2024-01-25T08:46:58.467605800Z"
    }
   },
   "id": "51a9d74bc11ed859"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "test_set1 = test_set1.batch(batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:47:05.750350Z",
     "start_time": "2024-01-25T08:47:05.707438600Z"
    }
   },
   "id": "45873b02849bdd69"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 4s 61ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions = autoencoder.predict(test_set1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:47:13.540460Z",
     "start_time": "2024-01-25T08:47:08.954840900Z"
    }
   },
   "id": "803d907bb198885a"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "reconstructions = reconstructions.reshape(-1,129,129)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:51:22.156505400Z",
     "start_time": "2024-01-25T08:51:22.091141600Z"
    }
   },
   "id": "37d95ab3d5015e6e"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "reconstruction_errors = tf.keras.losses.mse(reconstructions.reshape(-1, 129 * 129), \n",
    "                                            test_data1.reshape(-1, 129 * 129))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:53:05.943485200Z",
     "start_time": "2024-01-25T08:53:05.769947500Z"
    }
   },
   "id": "34148cee0358b87d"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.37772849, 0.35040021, 0.33243734, ..., 0.10774501, 0.10686203,\n       0.10507507])"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_errors.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T09:00:27.401397400Z",
     "start_time": "2024-01-25T09:00:27.341558300Z"
    }
   },
   "id": "2e39a4471b995398"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# 设定异常检测阈值\n",
    "error_threshold = np.percentile(reconstruction_errors.numpy(), 99)  # 假设异常值占5%"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:57:18.983037700Z",
     "start_time": "2024-01-25T08:57:18.922123400Z"
    }
   },
   "id": "e324c78f5d823cc9"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# 检测异常\n",
    "outliers = reconstruction_errors > error_threshold"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:57:19.494336400Z",
     "start_time": "2024-01-25T08:57:19.441474600Z"
    }
   },
   "id": "90edd14c57ea0f9"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "array([False, False, False, ..., False, False, False])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:57:20.368714900Z",
     "start_time": "2024-01-25T08:57:20.303540400Z"
    }
   },
   "id": "5765e0906cd14b4e"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T08:55:55.848598500Z",
     "start_time": "2024-01-25T08:55:55.802699900Z"
    }
   },
   "id": "d6f45dbb6da2e6c7"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "shot = np.load('D:/科大研究生生活/文章/2023.10后补充工作/数据/夏翔泽下载数据/output_gkfiles66011_67142/66011/PSIRZ.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T09:15:06.103660800Z",
     "start_time": "2024-01-25T09:15:06.002322Z"
    }
   },
   "id": "daadf669db0fd867"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "shot1 = tf.convert_to_tensor(shot,dtype=tf.float32)\n",
    "shot11 = tf.data.Dataset.from_tensor_slices(shot1)\n",
    "shot11 = shot11.map(lambda x: (preprocess_image(x)))\n",
    "shot11 = shot11.batch(batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T09:16:11.441565500Z",
     "start_time": "2024-01-25T09:16:11.364650800Z"
    }
   },
   "id": "f7b243d93af1d1f6"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions1 = autoencoder.predict(shot11)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T09:16:28.922137100Z",
     "start_time": "2024-01-25T09:16:28.609145Z"
    }
   },
   "id": "4bdabe2b9561da42"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "reconstruction_errors1 = tf.keras.losses.mse(reconstructions1.reshape(-1, 129 * 129), \n",
    "                                            shot.reshape(-1, 129 * 129))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T09:16:50.163057200Z",
     "start_time": "2024-01-25T09:16:50.081894500Z"
    }
   },
   "id": "a4944b4314d423bd"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.76738561, 0.56162232, 0.70253203, 0.51729373, 0.47522321,\n       0.39585598, 0.34694294, 0.32832788, 0.31118652, 0.2787368 ,\n       0.25999757, 0.24267284, 0.22269321, 0.20293254, 0.19012982,\n       0.18183247, 0.17654315, 0.17080666, 0.1665458 , 0.16424232,\n       0.16014433, 0.15823183, 0.15643035, 0.15381927, 0.15065232,\n       0.14772943, 0.14488151, 0.14160973, 0.13838509, 0.13421854,\n       0.13156297, 0.12803568, 0.12452771, 0.12126829, 0.11769959,\n       0.11446555, 0.11142852, 0.1082082 , 0.10528208, 0.10247849,\n       0.09943938, 0.0965258 , 0.09389726, 0.09127155, 0.08823413,\n       0.08571482, 0.08275791, 0.07981045, 0.07704219, 0.07463418,\n       0.07003785, 0.06592981, 0.06201367, 0.05847181, 0.05533423,\n       0.05192824, 0.04889249, 0.0458045 , 0.04278749, 0.03993524,\n       0.03668927, 0.03401839, 0.03139169, 0.02875711, 0.0264774 ,\n       0.02396065, 0.02163515, 0.01964228, 0.01753733, 0.01591739,\n       0.01444939, 0.01271006, 0.01136175, 0.01014233, 0.00925034,\n       0.00853495, 0.00766436, 0.00720601, 0.00679514, 0.00641973,\n       0.00657794, 0.00767625, 0.00936593, 0.01078814, 0.01341894,\n       0.01742979, 0.01279874, 0.01429514, 0.08201182, 0.22579425,\n       0.25193635, 0.02700451, 0.01940269, 0.020274  , 0.02108353,\n       0.10545061, 0.12882919, 0.15054075, 0.04986023, 0.00359147,\n       0.02729836, 0.08020889, 0.00397325, 0.0032604 , 0.00410047,\n       0.00395806, 0.00421874, 0.00403904, 0.00343263, 0.00389606,\n       0.00404974, 0.0029909 , 0.00332993, 0.00349222, 0.00322224])"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_errors1.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-25T09:16:58.465579500Z",
     "start_time": "2024-01-25T09:16:58.391776900Z"
    }
   },
   "id": "867fa9cbc586c1db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b859e205933db533"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
